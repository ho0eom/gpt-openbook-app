import os
import streamlit as st
from openai import OpenAI
from rapidfuzz import fuzz

# â€” OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (v1 ì¸í„°í˜ì´ìŠ¤) â€”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# â€” PDF/TXT í…ìŠ¤íŠ¸ ë¡œë“œ â€”
@st.cache_data
def load_text():
    with open("pdf_text/your_pdf.txt", "r", encoding="utf-8") as f:
        return f.read()

# â€” í˜ì´ì§€(ì²­í¬) ë‹¨ìœ„ë¡œ ë¶„ë¦¬ â€”
@st.cache_data
def split_pages(full_text: str):
    if "[Page " in full_text:
        raw = full_text.split("[Page ")
        pages = []
        for chunk in raw:
            chunk = chunk.strip()
            if not chunk:
                continue
            try:
                num_str, content = chunk.split("]", 1)
                pages.append((int(num_str), content.strip()))
            except ValueError:
                continue
        return pages
    else:
        chunks = []
        step = 2000
        for i in range(0, len(full_text), step):
            chunks.append((i // step + 1, full_text[i : i + step]))
        return chunks

# â€” rapidfuzzë¡œ ì˜¤íƒ€ ë‚´ì„± ìˆëŠ” í˜ì´ì§€ ê²€ìƒ‰ â€”
def search_best_page(query: str, pages: list[tuple[int, str]]):
    best_score, best = 0, (None, "")
    for num, txt in pages:
        score = fuzz.partial_ratio(query, txt)
        if score > best_score:
            best_score, best = score, (num, txt)
    return best  # (page_num, content)

# â€” GPTì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸° â€”
def ask_gpt(question: str, page_num: int, page_txt: str):
    system_prompt = (
        "ì•„ë˜ëŠ” ì‹œí—˜ìš© ì˜¤í”ˆë¶ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
        f"{page_num}ìª½ í…ìŠ¤íŠ¸ ì¼ë¶€ë¥¼ ë³´ê³  ì§ˆë¬¸ì— ë‹µí•˜ê³ , ë‹µì˜ ê·¼ê±° ë¬¸ì¥ë„ ê°™ì´ ì œì‹œí•˜ì„¸ìš”."
    )
    user_prompt = f"ì§ˆë¬¸: {question}\n\n```í˜ì´ì§€ ë‚´ìš© ì‹œì‘```\n{page_txt}\n```í˜ì´ì§€ ë‚´ìš© ë```"
    resp = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": user_prompt},
        ],
    )
    return resp.choices[0].message.content.strip()

# â€” Streamlit UI â€”
st.set_page_config(page_title="ğŸ“˜ ì˜¤í”ˆë¶ ì‹œí—˜ ì§ˆë¬¸ ë„ìš°ë¯¸")
st.title("ğŸ“˜ ì˜¤í”ˆë¶ ì‹œí—˜ ì§ˆë¬¸ ë„ìš°ë¯¸")
st.write("PDF/TXTì—ì„œ ê°€ì¥ ê´€ë ¨ ìˆëŠ” í˜ì´ì§€ë¥¼ ê³¨ë¼ AIê°€ ë‹µí•˜ê³  ê·¼ê±°ë¥¼ ë“œë ¤ìš”.")

question = st.text_input("â“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

if question:
    full = load_text()
    pages = split_pages(full)
    page_num, page_txt = search_best_page(question, pages)

    if page_txt:
        with st.spinner(f"{page_num}ìª½ ë‚´ìš©ì„ ë¶„ì„ ì¤‘..."):
            answer = ask_gpt(question, page_num, page_txt[:1500])
        st.subheader(f"âœ… GPTì˜ ë‹µë³€ (í˜ì´ì§€ {page_num})")
        st.write(answer)
    else:
        st.error("ê´€ë ¨ëœ í˜ì´ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
